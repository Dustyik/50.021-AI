{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CY AI homework 2 - neural networks",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUbEmuvZJxlI"
      },
      "source": [
        "# PyTorch - homework 2: neural networks\n",
        "\n",
        "-- Prof. Dorien Herremans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efS07mO7J6AR"
      },
      "source": [
        "Please run the whole notebook with your code and submit the `.ipynb` file on eDimension that includes your answers [so after you run it]. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJpzFaX0J6Zz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e59e9231-3a66-4c46-845a-7e25efbc2004"
      },
      "source": [
        "from termcolor import colored\n",
        "\n",
        "student_number=\"1003391\"\n",
        "student_name=\"Tan Chia Yik\"\n",
        "\n",
        "print(colored(\"Homework by \"  + student_name + ', number: ' + student_number,'red'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mHomework by Tan Chia Yik, number: 1003391\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xDkwBg8LKQ_"
      },
      "source": [
        " ## Question 1 -- XOR neural network [3pts]\n",
        "\n",
        "a) Train an (at least) 2-layer neural network that can solve the XOR problem. Hint: be sure to check both this week and last week's lab. \n",
        "\n",
        "b) Check the predictions resulting from your model in the second code box below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BINvhm-PLKak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51b6067b-8856-47fd-bad8-70f0d3c8db86"
      },
      "source": [
        "# load your data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# training set of input X and labels Y\n",
        "X = torch.Tensor([[0,0],[0,1], [1,0], [1,1]])\n",
        "Y = torch.Tensor([0,1,1,0]).view(-1,1)\n",
        "\n",
        "# name your model xor\n",
        "class XOR(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(XOR, self).__init__()\n",
        "    self.linear_first = nn.Linear(input_size, hidden_size)\n",
        "    self.linear_second = nn.Linear(hidden_size, num_classes)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear_first(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_second(out)\n",
        "    out = torch.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "input_size = 2\n",
        "hidden_size = 3\n",
        "num_classes = 1\n",
        "XOR_clf = XOR(input_size, hidden_size, num_classes)\n",
        "\n",
        "# define your model loss function, optimizer, etc. \n",
        "lr_rate = 0.001\n",
        "loss_function = nn.BCELoss() \n",
        "optimizer = torch.optim.Adam(XOR_clf.parameters(), lr=lr_rate)\n",
        "\n",
        "# train the model\n",
        "\n",
        "epochs = 10001 \n",
        "steps = X.size(0) \n",
        "\n",
        "for i in range(epochs):  \n",
        "    optimizer.zero_grad() \n",
        "    output_y = XOR_clf(X)#forward pass\n",
        "\n",
        "    loss = loss_function(output_y, Y) #calculate the loss\n",
        "    loss.backward() #backprop\n",
        "    optimizer.step() #does the update\n",
        "\n",
        "    if i % 1000 == 0:\n",
        "        print (\"Epoch: {0}, Loss: {1}, \".format(i, loss.data))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 0.7172043323516846, \n",
            "Epoch: 1000, Loss: 0.504838228225708, \n",
            "Epoch: 2000, Loss: 0.14360883831977844, \n",
            "Epoch: 3000, Loss: 0.058326609432697296, \n",
            "Epoch: 4000, Loss: 0.02836252935230732, \n",
            "Epoch: 5000, Loss: 0.015296418219804764, \n",
            "Epoch: 6000, Loss: 0.00876498594880104, \n",
            "Epoch: 7000, Loss: 0.005214254837483168, \n",
            "Epoch: 8000, Loss: 0.0031792016234248877, \n",
            "Epoch: 9000, Loss: 0.001971431775018573, \n",
            "Epoch: 10000, Loss: 0.0012360757682472467, \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51Ra1T6n2r_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d614d9e9-018a-4f2b-f362-bbbed2736014"
      },
      "source": [
        "# test your model using the following functions (make sure the output is printed and saved when you submit this notebook):\n",
        "# depending on how you defined your network you may need to slightly tweek the below prediction function\n",
        "\n",
        "test = [[0,0],[0,1],[1,1],[1,0]]\n",
        "\n",
        "for trial in test: \n",
        "  Xtest = torch.Tensor(trial)\n",
        "  y_hat = XOR_clf(Xtest)\n",
        "\n",
        "  if y_hat > 0.5:\n",
        "    prediction = 1\n",
        "  else: \n",
        "    prediction = 0\n",
        "\n",
        "  print(\"{0} xor {1} = {2}\".format(int(Xtest[0]), int(Xtest[1]), prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 xor 0 = 0\n",
            "0 xor 1 = 1\n",
            "1 xor 1 = 0\n",
            "1 xor 0 = 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqIqD5ZzyUOW"
      },
      "source": [
        "## Question 2  [2pts]\n",
        "\n",
        "Imagine a neural network model for a multilabel classification task. \n",
        "\n",
        "a) Which loss function should you use?\n",
        "\n",
        "b) The resulting trained modal has a high variance error. Give 4 possible solutions to improve the model. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzye9G18PQ0c"
      },
      "source": [
        "```\n",
        "[your answer here, no coding required]\n",
        "\n",
        "* answer A\n",
        "\n",
        "BCEWithLogitsLoss\n",
        "\n",
        "highvariance - overfitting model\n",
        "* answer B\n",
        "  - 1 Regularization\n",
        "  - 2 Dropout\n",
        "  - 3 Early Stopping\n",
        "  - 4 Data augmentation\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcceOSnjjSHf"
      },
      "source": [
        "## Question 3 - Improve hit classification [5pts]\n",
        "\n",
        "Remember the hit predicton dataset from last week? \n",
        "\n",
        "a) Improve the model using a multiplayer perceptron. \n",
        "\n",
        "b) Make sure to run your models on the GPU. \n",
        "\n",
        "c) Tweek the hyperparameters such as number of nodes or layers, or other. Show two possible configurations and explain which works better and very briefly explain why this may be the case. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-jkJDTdjSRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "546e41bf-ce53-4742-d569-9e6909933e7c"
      },
      "source": [
        "# code your model 1\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "# load data\n",
        "all_data = pd.read_csv(io.BytesIO(uploaded['herremans_hit_1030training.csv']))\n",
        "labels = all_data.iloc[:,-1] #Gets the target values, 1 means top 10 hit song, 0 means not top 10 hit song\n",
        "labels = torch.Tensor(labels.values).reshape(-1,1)\n",
        "train_data = all_data.drop('Topclass1030', axis=1) #Removes labels from dataset\n",
        "train_data = torch.Tensor(train_data.values) \n",
        "\n",
        "num_input_features = train_data.size(1) #has an output dimension of 1\n",
        "\n",
        "# define logistic regression model\n",
        "class MulLayerPercp_model1(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size = 1):\n",
        "    super(MulLayerPercp_model1, self).__init__()\n",
        "    self.linear_first_layer = nn.Linear(input_size, hidden_size)\n",
        "    self.linear_second_layer = nn.Linear(hidden_size, output_size)\n",
        "    self.relu = nn.ReLU() #ReLU resolves the vanishing gradient problem, as the derivitive of the relu function is 1, and ReLU is the defauly activation function in multilater perceptron and CNN\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.linear_first_layer(x) \n",
        "    out = self.relu(out)\n",
        "    out = self.linear_second_layer(out)\n",
        "    out = self.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "hidden_size = 15\n",
        "MulLayerPercp_clf_1 = MulLayerPercp_model1(num_input_features, hidden_size)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "epochs = 1001\n",
        "learning_rate = 0.01\n",
        "loss_function = nn.BCELoss() #Mean Squared Error loss\n",
        "optimizer = torch.optim.SGD(MulLayerPercp_clf_1.parameters(), lr=learning_rate)\n",
        "\n",
        "for i in range(epochs):\n",
        "    MulLayerPercp_clf_1.train()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward Pass\n",
        "    output_y = MulLayerPercp_clf_1(train_data)\n",
        "\n",
        "    # Compute Loss\n",
        "    loss = loss_function(output_y, labels)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Epoch - {i} , Loss - {loss.item()}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch - 0 , Loss - 0.6963269114494324\n",
            "Epoch - 100 , Loss - 0.6321107149124146\n",
            "Epoch - 200 , Loss - 0.6132636666297913\n",
            "Epoch - 300 , Loss - 0.5987904667854309\n",
            "Epoch - 400 , Loss - 0.5847398042678833\n",
            "Epoch - 500 , Loss - 0.5707181096076965\n",
            "Epoch - 600 , Loss - 0.5575959086418152\n",
            "Epoch - 700 , Loss - 0.5456567406654358\n",
            "Epoch - 800 , Loss - 0.5349549651145935\n",
            "Epoch - 900 , Loss - 0.5254961252212524\n",
            "Epoch - 1000 , Loss - 0.5171141624450684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIDPTKcFkETc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d32d4f9-aaf0-4ba4-c2a2-e7a2ffa9cbe9"
      },
      "source": [
        "# evaluate model 1 (called model1 here)\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "def run_evaluation(my_model):\n",
        "\n",
        "  test = pd.read_csv(io.BytesIO(uploaded['herremans_hit_1030training.csv']))\n",
        "  labels = test.iloc[:,-1]\n",
        "  test = test.drop('Topclass1030', axis=1)\n",
        "  testdata = torch.Tensor(test.values)\n",
        "  testlabels = torch.Tensor(labels.values).view(-1,1)\n",
        "\n",
        "  TP = 0\n",
        "  TN = 0\n",
        "  FN = 0\n",
        "  FP = 0\n",
        "\n",
        "  for i in range(0, testdata.size()[0]): \n",
        "    # print(testdata[i].size())\n",
        "    Xtest = torch.Tensor(testdata[i])\n",
        "    y_hat = my_model(Xtest)\n",
        "    \n",
        "    if y_hat > 0.5:\n",
        "      prediction = 1\n",
        "    else: \n",
        "      prediction = 0\n",
        "\n",
        "    if (prediction == testlabels[i]):\n",
        "      if (prediction == 1):\n",
        "        TP += 1\n",
        "      else: \n",
        "        TN += 1\n",
        "\n",
        "    else:\n",
        "      if (prediction == 1):\n",
        "        FP += 1\n",
        "      else: \n",
        "        FN += 1\n",
        "\n",
        "  print(\"True Positives: {0}, True Negatives: {1}\".format(TP, TN))\n",
        "  print(\"False Positives: {0}, False Negatives: {1}\".format(FP, FN))\n",
        "  rate = TP/(FN+TP)\n",
        "  print(\"Class specific accuracy of correctly predicting a hit song is {0}\".format(rate))\n",
        "\n",
        "run_evaluation(MulLayerPercp_clf_1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positives: 183, True Negatives: 59\n",
            "False Positives: 59, False Negatives: 20\n",
            "Class specific accuracy of correctly predicting a hit song is 0.9014778325123153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xghPDDNmkHn2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed67467-fd12-4e00-ab38-33d5ae8d6778"
      },
      "source": [
        "# code your model 2\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "# load data\n",
        "all_data = pd.read_csv(io.BytesIO(uploaded['herremans_hit_1030training.csv']))\n",
        "labels = all_data.iloc[:,-1] #Gets the target values, 1 means top 10 hit song, 0 means not top 10 hit song\n",
        "labels = torch.Tensor(labels.values).reshape(-1,1)\n",
        "train_data = all_data.drop('Topclass1030', axis=1) #Removes labels from dataset\n",
        "train_data = torch.Tensor(train_data.values) \n",
        "\n",
        "num_input_features = train_data.size(1) #has an output dimension of 1\n",
        "\n",
        "# define logistic regression model\n",
        "class MulLayerPercp_model2(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size = 1):\n",
        "    super(MulLayerPercp_model2, self).__init__()\n",
        "    self.linear_first_layer = nn.Linear(input_size, hidden_size)\n",
        "    self.linear_second_layer = nn.Linear(hidden_size, hidden_size)\n",
        "    self.linear_third_layer = nn.Linear(hidden_size, hidden_size)\n",
        "    self.linear_fourth_layer = nn.Linear(hidden_size, output_size)\n",
        "    self.relu = nn.ReLU() #ReLU resolves the vanishing gradient problem, as the derivitive of the relu function is 1, and ReLU is the defauly activation function in multilater perceptron and CNN\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.linear_first_layer(x) \n",
        "    out = self.relu(out)\n",
        "    out = self.linear_second_layer(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_third_layer(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear_fourth_layer(out)\n",
        "    out = self.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "hidden_size = 15\n",
        "MulLayerPercp_clf_2 = MulLayerPercp_model2(num_input_features, hidden_size)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "epochs = 1001\n",
        "learning_rate = 0.01\n",
        "loss_function = nn.BCELoss() #Mean Squared Error loss\n",
        "optimizer = torch.optim.SGD(MulLayerPercp_clf_2.parameters(), lr=learning_rate)\n",
        "\n",
        "for i in range(epochs):\n",
        "    MulLayerPercp_clf_2.train()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward Pass\n",
        "    output_y = MulLayerPercp_clf_2(train_data)\n",
        "\n",
        "    # Compute Loss\n",
        "    loss = loss_function(output_y, labels)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Epoch - {i} , Loss - {loss.item()}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch - 0 , Loss - 0.714074969291687\n",
            "Epoch - 100 , Loss - 0.6905967593193054\n",
            "Epoch - 200 , Loss - 0.6762173175811768\n",
            "Epoch - 300 , Loss - 0.6669715642929077\n",
            "Epoch - 400 , Loss - 0.6602802276611328\n",
            "Epoch - 500 , Loss - 0.6552578806877136\n",
            "Epoch - 600 , Loss - 0.6511135101318359\n",
            "Epoch - 700 , Loss - 0.6470938920974731\n",
            "Epoch - 800 , Loss - 0.6424397826194763\n",
            "Epoch - 900 , Loss - 0.6372448801994324\n",
            "Epoch - 1000 , Loss - 0.6311960220336914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAIifiHJkHyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bee4eea-ba4d-4d18-a9c7-3deeeab7ed5d"
      },
      "source": [
        "# evaluate model 2 (called model2 here)\n",
        "\n",
        "run_evaluation(MulLayerPercp_clf_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positives: 203, True Negatives: 0\n",
            "False Positives: 118, False Negatives: 0\n",
            "Class specific accuracy of correctly predicting a hit song is 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPsxbT0KkGs1"
      },
      "source": [
        "Which works better and why do you think this may be (very briefly)? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GzjI77HkSwH"
      },
      "source": [
        "**[your answer here, also please summarise the differences between your two models]**\n",
        "\n",
        "The second model works better, with close to perfect prediction, while the first model has a prediction of about 90% accuracy. both models use stochastic gradient descent as optimisers, and both have a hidden layer size of 15.\n",
        "\n",
        "However, model 1 has 1 hidden layer, but model 2 has 3 hidden layers. As the second model has more parameters, model 2 is more complex, and it generalises better. Model 1 has less parameters, suggesting that the model is slightly bias, and doesnt do well outside of the train set. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh5O8qS_khug"
      },
      "source": [
        "Additionally, submit your results [here](https://forms.gle/NtJJEE7Wm5ZRM3Je7) for 'Class specific accuracy of correctly predicting a hit song' and see if you got the best performance of the class! Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "prMFbRqfwcBq",
        "outputId": "8686ffa9-bcc4-478d-f885-00e404f7d151"
      },
      "source": [
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8d2c360f-e4ce-40e2-83e5-0c4d8b44d9d5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8d2c360f-e4ce-40e2-83e5-0c4d8b44d9d5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving herremans_hit_1030training.csv to herremans_hit_1030training.csv\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}